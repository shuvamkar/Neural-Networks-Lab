3 6         #number of layers, number of nodes
2 identity  #nodes in layer 0 (input)
3 ReLU      #nodes in layer 1 and applies ReLU activation
1 sigmoid   #nodes in layer 2 (output) and applies sigmoid activation
9           #number of weights to load
0 2 1       #edge 0->2 has weight 1
0 3 -3      #edge 0->3 has weight -3
0 4 2.2     #edge 0->4 has weight 2.2
1 2 6       #edge 1->2 has weight 6
1 3 0       #edge 1->3 has weight 0
1 4 -1.1    #edge 1->4 has weight -1.1
2 5 0       #edge 2->5 has weight 0
3 5 3.4     #edge 3->5 has weight 3.4
4 5 2       #edge 4->5 has weight 2
4           #number of biases to load
2 2         #node 2 has bias 2
3 -1.1      #node 3 has bias -1.1
4 3.9       #node 4 has bias 3.9
5 0.1       #node 5 has bias 0.1